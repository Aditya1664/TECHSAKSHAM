{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41bf41ee-ff24-4cee-86cd-03fcef0cac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processed images have been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import cv2  # OpenCV library for image processing\n",
    "import numpy as np  # NumPy for numerical operations\n",
    "from rembg import remove  # rembg for background removal\n",
    "from PIL import Image  # PIL (Pillow) for handling images\n",
    "\n",
    "# ===================== STEP 1: Load Haar Cascade for Face Detection =====================\n",
    "# Haar Cascade is a pre-trained model for face detection in OpenCV.\n",
    "# It detects faces based on features learned from positive and negative samples.\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# ===================== STEP 2: Read the Image =====================\n",
    "# Define the path of the input image (update the path as per your file location)\n",
    "image_path = \"D:\\\\Project\\\\image1.jpg\"\n",
    "\n",
    "# Read the image using OpenCV (cv2.imread reads the image as a NumPy array)\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# If the image file is not found or cannot be read, exit the program\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Check the file path.\")  # Print an error message\n",
    "    exit()  # Exit the program\n",
    "\n",
    "# ===================== STEP 3: Convert Image to Grayscale =====================\n",
    "# Many image processing tasks (like edge detection & face detection) work better in grayscale.\n",
    "# Grayscale reduces computational cost by removing color information.\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert BGR image to grayscale\n",
    "\n",
    "# ===================== STEP 4: Apply Gaussian Blur =====================\n",
    "# Blurring helps in noise reduction, which improves edge detection.\n",
    "# The kernel size (35, 35) determines the level of blurring.\n",
    "blurred_image = cv2.GaussianBlur(image, (35, 35), 0)\n",
    "\n",
    "# ===================== STEP 5: Apply Edge Detection (Canny Algorithm) =====================\n",
    "# Canny edge detection finds edges by detecting intensity gradients in the image.\n",
    "# Parameters: \n",
    "# - 50 (first threshold): Lower bound for edge detection.\n",
    "# - 150 (second threshold): Upper bound for strong edges.\n",
    "edges = cv2.Canny(image, 50, 150)\n",
    "\n",
    "# ===================== STEP 6: Detect Faces in the Image =====================\n",
    "# We use the Haar Cascade face detector on the grayscale image.\n",
    "# Parameters:\n",
    "# - scaleFactor=1.1: Reduces the size of the image at each step to detect faces at different scales.\n",
    "# - minNeighbors=5: Higher value results in fewer detections but reduces false positives.\n",
    "# - minSize=(30, 30): Minimum size of detected faces.\n",
    "faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# ===================== STEP 7: Draw Rectangles Around Detected Faces =====================\n",
    "# Loop through each detected face and draw a green rectangle around it.\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 3)  # (0, 255, 0) represents green color\n",
    "\n",
    "# ===================== STEP 8: Convert Grayscale Image to BGR (Fix for OpenCV pencilSketch) =====================\n",
    "# OpenCV's pencilSketch function requires a 3-channel (BGR) image, so we convert grayscale to BGR.\n",
    "gray_bgr = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# ===================== STEP 9: Apply Pencil Sketch Effect =====================\n",
    "# OpenCV provides a built-in pencil sketch effect.\n",
    "# Parameters:\n",
    "# - sigma_s=60: Controls the smoothness of the sketch.\n",
    "# - sigma_r=0.07: Determines the amount of detail preserved.\n",
    "# - shade_factor=0.05: Controls shading.\n",
    "sketch_gray, sketch_color = cv2.pencilSketch(gray_bgr, sigma_s=60, sigma_r=0.07, shade_factor=0.05)\n",
    "\n",
    "# ===================== STEP 10: Background Removal Using rembg (U^2-Net) =====================\n",
    "# rembg uses a deep learning model (U^2-Net) to accurately remove the background.\n",
    "# Open the image using PIL (Pillow), as rembg expects PIL images.\n",
    "input_image = Image.open(image_path)\n",
    "\n",
    "# Apply background removal (rembg automatically removes everything except the subject)\n",
    "output_image = remove(input_image)\n",
    "\n",
    "# Convert the result from RGBA (rembg output) to BGR (OpenCV format)\n",
    "output_image = cv2.cvtColor(np.array(output_image), cv2.COLOR_RGBA2BGR)\n",
    "\n",
    "# ===================== STEP 11: Save the Processed Images =====================\n",
    "# We save different versions of the processed image in the output directory.\n",
    "cv2.imwrite(\"D:\\\\Project\\\\gray_image.jpg\", gray_image)  # Save grayscale image\n",
    "cv2.imwrite(\"D:\\\\Project\\\\blurred_image.jpg\", blurred_image)  # Save blurred image\n",
    "cv2.imwrite(\"D:\\\\Project\\\\edges.jpg\", edges)  # Save edge-detected image\n",
    "cv2.imwrite(\"D:\\\\Project\\\\face_detected.jpg\", image)  # Save face-detection output\n",
    "cv2.imwrite(\"D:\\\\Project\\\\pencil_sketch.jpg\", sketch_gray)  # Save pencil sketch effect\n",
    "cv2.imwrite(\"D:\\\\Project\\\\background_removed.jpg\", output_image)  # Save background-removed image\n",
    "\n",
    "print(\"All processed images have been saved successfully!\")  # Print confirmation message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c9c2b-2b26-410a-a852-22697acca270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
